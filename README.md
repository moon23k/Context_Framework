## Sum BERT

BERT is widely used in many NLP Down Streaming Task via Transfer Learning. However transfering BERT into Sequence Genreration Task is not straightforward. This is especially true when dealing with long sequences, such as Text Summarization. To mend this problem BERT-based Text Summarization framework, named **BERTSUM** has been proposed. 


<br><br>

## Strategies

**Fine Tuning** <br>


<br>

**Featuring** <br>

<br>


<br><br>

## Experimental Setup

<br><br>

## Result

<br><br>

## How to use
```
git clone 
```

```
python3 setup.py
```

```
python3 run.py -mode [train, test, inference] -strategy [fine, feat]
```

<br><br>

## Reference
[**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://arxiv.org/abs/1810.04805)

[**Text Summarization with Pretrained Encoders**](https://arxiv.org/abs/1908.08345)

[**Incorporating BERT into Neural Machine Translation**](https://arxiv.org/abs/2002.06823)

[**Hierarchical Transformers for Long Document Classification**](https://arxiv.org/abs/1910.10781)

<br>
